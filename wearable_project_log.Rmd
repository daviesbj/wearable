Brian Davies' Data Cleaning Project Log
=======================================

Investigating the data
----------------------

I started by downloading and unzipping the ZIP file mentioned in the course instructions
Assuming I've already created a working directory

```{r get_data}
date()
workdir = "~/wearable"
setwd(workdir)
source_URL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
# download.file(source_URL,destfile="wearable.zip",method="curl")
# unzip("wearable.zip")
date()
```

OK, let's look in the directory __UCI HAR Dataset__. I'm going to do this in the shell.

Right, in the top-level dir we've got

File                  |  Description
----------------------|-------------
README.txt            | Meh
features.txt          | Numbered list of feature descriptors -- 561 of 'em
features_info.txt     | Some info about the features
activity_labels.txt   | Key from 1-6 to single-token activity descriptions
test/                 | Actual data (directory)
train/                | another

Here's a function I wrote to count lines in a file

```{r define_wcml}
wcml <- function(fname){ length(readLines(fname)) }
```

Looking in __test__ or __train__, we've got

File                | Description
--------------------|------------
subject_train.txt   | List of subjects, one per test
X_train.txt         | Feature values for each test, 561 values per line
y_train.txt         | I'm guessing these are the activity identifiers
Inertial Signals/   | Directory for raw data

And in that last directory, we've got the following files:

* body_acc_x_test.txt
* body_acc_y_test.txt
* body_acc_z_test.txt
* body_gyro_x_test.tx
* body_gyro_y_test.txt
* body_gyro_z_test.txt
* total_acc_x_test.txt
* total_acc_y_test.txt
* total_acc_z_test.txt

Each has the same number of lines as X_train.txt etc., and 128 numbers per column -- so they will be the raw
transducer data.

The annoying thing about this dataset as supplied is that the dataset identifier, __train__ or __test__, is
not only encoded into the directory containing the dataset, but at various other places along the way in
the individual filenames. So if I write a routine just to read one dataset, I'll forever be interpolating
the dataset name in filenames as I go along.

So I decided to write a separate R function to generate all the filenames for me and return a nice list
that I could just scoop up, one at a time. Along the way, I decided to add some integrity checks, basically
that there were the right numbers of rows & columns in each file. I ended up writing this lot, which
lives in the R source file __file_info.R__:

```{r define_file_info}
## file_info
## Check all the files required to build the dataset.
## -- Assemble their basenames and dirnames
## -- Check that they exist
## -- Check their contents are roughly correct (mainly # of rows & columns)
## -- Aggregate these results in a data frame for return from this routine
file_info <- function( dataset, source.dir = "~/wearable/UCI HAR Dataset", verbose = TRUE ){
  
  ## Guard against zealous user leaving / on end of source.dir
  if( length(grep( "[/]$", source.dir ) ) != 0 ){
    if( verbose ) warning( "Removing trailing slash from source.dir=", source.dir )
    source.dir <- substr( source.dir, 1, length(source.dir)-1 )  
  }
  
  ## Check it exists
  if( ! file.exists(source.dir)){
    stop( "Can't find source.dir=", source.dir )
  }
  
  ## dataset dir name, check it exists
  set.dir <- paste( source.dir, "/", dataset, sep="" )
  if( ! file.exists(set.dir)){
    stop( "Can't find dataset directory ", set.dir )
  }
  
  ## Inertial data dir, check it exists
  inert.dir <- paste( set.dir, "/Inertial Signals", sep="" )
  if( ! file.exists(inert.dir)){
    stop( "Can't find Inertial Signals directory ", inert.dir )
  }
  
  ## First three files
  ## First one being activity.label.txt
  ## Use first frame to return overall result, hence name
  if( verbose ) message( " ... checking activity_labels.txt" )
  result.frame <- check_HAR_file( dir=source.dir, name="activity_labels.txt", cols_expected=2 )
  if( ! result.frame$ok ) warning( "Something wrong with activity_labels.txt")
  
  ## Feature descriptors
  if( verbose ) message( " ... checking features.txt" )
  feature.frame <- check_HAR_file( dir=source.dir, name="features.txt", cols_expected=2 )
  if( ! feature.frame$ok ) warning( "Something wrong with features.txt")
  ## Start combining frames
  result.frame <- rbind.names(list(result.frame,feature.frame))
  
  ## subject identifiers for the study
  ## This tells us how many records should be in the othr files
  subject.file <- paste( "subject_", dataset, ".txt", sep="" )
  if( verbose ) message( " ... checking ", subject.file )
  subject.frame <- check_HAR_file( dir=set.dir, name=subject.file, cols_expected=1 )
  if( ! subject.frame$exists ) stop ( "Can't find ", subject.file, " -- no point going on" )
  result.frame <- rbind.names(list(result.frame,subject.frame))
  
  ## Important numbers!
  ntest <- result.frame[subject.file,"rows"]
  if( verbose ) message( subject.file," contains ", ntest, " test records" )
  nfeature <- result.frame[ "features.txt","rows"]
  if( verbose ) message( "features.txt contains ", nfeature, " feature descriptors" )
  
  ## Next two files ...
  X.file <- paste( "X_", dataset, ".txt", sep="" )
  if( verbose ) message( " ... checking ", X.file )
  X.frame <- check_HAR_file( dir=set.dir, name = X.file, rows_expected = ntest, cols_expected = nfeature )
  if( ! X.frame$ok ) warning( "Something wrong with ", X.file )
  result.frame <- rbind.names(list(result.frame,X.frame))
  
  y.file <- paste( "y_", dataset, ".txt", sep="" )
  if( verbose ) message( " ... checking ", y.file )
  y.frame <- check_HAR_file( dir=set.dir, name = y.file, rows_expected = ntest )
  if( ! y.frame$ok ) warning( "Something wrong with ", y.file )
  result.frame <- rbind.names(list(result.frame,y.frame))
  
  ## And loop over Inertial Signals files ...
  inert.types <- c( "body_acc", "body_gyro", "total_acc" )
  for( inert.type in inert.types ){
    for( axis in c( "x", "y", "z") ){
      inert.file <- paste( inert.type, "_", axis, "_", dataset, ".txt", sep="" )
      if( verbose ) message( " ... checking ", inert.file )
      inert.frame <- check_HAR_file( dir=inert.dir, name = inert.file, rows_expected = ntest, cols_expected=128)
      if( ! inert.frame$ok ) warning ( "Something wrong with ", inert.file )
      result.frame <- rbind.names(list(result.frame,inert.frame))
    }
  }
  
result.frame
}

## check_HAR_file
## Generates full filename, does existence check, optionally check specified number of rows and columns
## crack=TRUE  forces row/column count even if not requested
check_HAR_file <- function( dir=NULL, name=NULL, rows_expected=NULL, cols_expected=NULL, crack=FALSE ){
  
  if( is.null(dir) | is.null(name)) stop( "Must specify AT LEAST dir and name in check_HAR_file" )
  
  fullpath <- paste( dir, "/", name, sep="" )
  if( ! file.exists(fullpath)){
    return(data.frame( row.names=name, file=fullpath, exists=FALSE, ok=FALSE, rows=NA, columns=NA ))}
  
  if( is.null(rows_expected) & is.null(cols_expected) & ! crack ){
    return(data.frame( row.names=name, file=fullpath, exists=TRUE, ok=TRUE, rows=NA, columns=NA ))}

  the.frame <- read.table(fullpath,header=FALSE)
  the.dims <- dim(the.frame)
  actual.rows <- the.dims[1]
  actual.cols <- the.dims[2]
  is_ok <- ((( is.null(rows_expected)) || ( actual.rows == rows_expected )) &
           (( is.null(cols_expected)) || ( actual.cols == cols_expected )))
  return(data.frame( row.names=name, file=fullpath, exists=TRUE, ok=is_ok, rows=actual.rows, columns=actual.cols ))
}

## rbind.names
## This is a little service routine to join dataframes with row labels
rbind.names <- function(framelist){
  require(plyr)
  temp <- rbind.fill(framelist)
  rownames(temp) <- unlist(lapply(framelist, row.names))
  temp
}
```

Note that I wrote a lower-level function __check_HAR_file__ to do the biz on the specified file.
So when we run this, we get a nice data frame like this:

```
> file_info("test", verbose=FALSE)
                                                                                      file exists   ok rows columns
activity_labels.txt                         ~/wearable/UCI HAR Dataset/activity_labels.txt   TRUE TRUE    6       2
features.txt                                       ~/wearable/UCI HAR Dataset/features.txt   TRUE TRUE  561       2
subject_test.txt                          ~/wearable/UCI HAR Dataset/test/subject_test.txt   TRUE TRUE 2947       1
X_test.txt                                      ~/wearable/UCI HAR Dataset/test/X_test.txt   TRUE TRUE 2947     561
y_test.txt                                      ~/wearable/UCI HAR Dataset/test/y_test.txt   TRUE TRUE 2947       1
body_acc_x_test.txt   ~/wearable/UCI HAR Dataset/test/Inertial Signals/body_acc_x_test.txt   TRUE TRUE 2947     128
body_acc_y_test.txt   ~/wearable/UCI HAR Dataset/test/Inertial Signals/body_acc_y_test.txt   TRUE TRUE 2947     128
body_acc_z_test.txt   ~/wearable/UCI HAR Dataset/test/Inertial Signals/body_acc_z_test.txt   TRUE TRUE 2947     128
body_gyro_x_test.txt ~/wearable/UCI HAR Dataset/test/Inertial Signals/body_gyro_x_test.txt   TRUE TRUE 2947     128
body_gyro_y_test.txt ~/wearable/UCI HAR Dataset/test/Inertial Signals/body_gyro_y_test.txt   TRUE TRUE 2947     128
body_gyro_z_test.txt ~/wearable/UCI HAR Dataset/test/Inertial Signals/body_gyro_z_test.txt   TRUE TRUE 2947     128
total_acc_x_test.txt ~/wearable/UCI HAR Dataset/test/Inertial Signals/total_acc_x_test.txt   TRUE TRUE 2947     128
total_acc_y_test.txt ~/wearable/UCI HAR Dataset/test/Inertial Signals/total_acc_y_test.txt   TRUE TRUE 2947     128
total_acc_z_test.txt ~/wearable/UCI HAR Dataset/test/Inertial Signals/total_acc_z_test.txt   TRUE TRUE 2947     128
> 
```

Note that each line in that frame comes from a single call to __check_HAR_FILE__, and the results
are then welded together into a single frame. Note also the following:

* __test__ all over the place (same if you ask for __train__)
* The obvious regularities e.g. 561 rows in __features.txt__ and 561 columns in __X_train.txt__

If you got a THIRD dataset that you wanted to integrate with __test__ and __train__, __file_info__ would be
a useful tool to make sure your data are complete before you try it.

Loading the data
----------------

OK, so I want to load __test__ and __train__ into two frames with the same column names, that I can
then glue together, one on top of another. And to do _that_, I need to load each one in turn.

_The next few chunks of code need to be executed in the right place -- typically, start at the
directory containing the first file_

Let's starts out loading the activity data from __y_test.txt__ and transforming it from numeric
to the codes given in __activity_labels.txt__. I'm going to assume that factors are OK.

```{r read_and_convert_y}
setwd("~/wearable/UCI HAR Dataset")
activity_labels <- read.table("activity_labels.txt")
setwd("test")
y <- read.table("y_test.txt")
y.factor <- activity_labels$V2[y$V1]
```

Another tricky reading task is to read __X_test.txt__ and turn it into a dataframe with column
headings corresponding to the descriptors in __features.txt__

```{r read_and_label_X}
setwd("~/wearable/UCI HAR Dataset")
feature.desc <- read.table("features.txt")
setwd('test')
X_test <- read.table("X_test.txt")
colnames(X_test) <- feature.desc$V2
```

I'm guessing I'll also be wanting to load the raw sensor data. I'm going to give it
colum headings like __body_acc_x.001__ to __body_acc_x.128__ so that it will be
possible in principle to extract the raw data in time series order.

```{r read_and_label_raw_data}
setwd("~/wearable/UCI HAR Dataset/test/Inertial Signals")
body.acc <- read.table("body_acc_x_test.txt")
what <- "body_acc_x"
acc.labels <- sapply( c(1:128), function(x){ sprintf( paste( what, '.', "%03d", sep="" ), x ) } )
colnames(body.acc) <- acc.labels
```

The rest is just a matter of welding things together. So I'll write a routine __assemble_dataset()__ to do it.

```{r define_assemble_dataset}
## assemble_dataset
## Returns a dataframe for a UCI HAR dataset contained in & below the directory that the distribution unzips into
## Key files in unzip directory, per-set fils in named subdirectory
## Checks file availability, and if so assembles the dataset
## Changes activity to a factor, and adds headings to 561 feature values and 3x3x128 raw data values per record
## Returns a dataframe, optionally saves it to a file
assemble_dataset <- function( set.name, source.dir = "~/wearable/UCI HAR Dataset", verbose=TRUE, savefile = "" ){

if( verbose ) message( " ... checking file availability for dataset '", set.name, "'" )
file.list <- file_info( set.name, source.dir = source.dir, verbose = verbose )
if( any( ! file.list$ok) ) error( "Something wrong with data files -- run file_info and investigate")
if( verbose ) message( " ... looks good!" )

if( verbose ) message( " ... reading ", "activity_labels.txt" )
activity_labels.frame <- read.table( as.character(file.list["activity_labels.txt",]$file) )

if( verbose ) message( " ... reading ", "features.txt" )
features_desc.frame   <- read.table( as.character(file.list["features.txt",]$file) )

subject.file <- paste( "subject_", set.name, ".txt", sep="" )
if( verbose ) message( " ... reading ", subject.file )
subject.frame <- read.table( as.character(file.list[subject.file,]$file) )
colnames(subject.frame)<-c('subject')

y.file <- paste( "y_", set.name, ".txt", sep="" )
if( verbose ) message( " ... reading ", y.file )
y.frame <- read.table( as.character(file.list[y.file,]$file) )
y.factor <- activity_labels.frame$V2[y.frame$V1]
y.frame2 <- as.data.frame(y.factor)
colnames(y.frame2) <- c('activity')

X.file <- paste( "X_", set.name, ".txt", sep="" )
if( verbose ) message( " ... reading ", X.file )
X.frame <- read.table( as.character(file.list[X.file,]$file) )
colnames(X.frame) <- features_desc.frame$V2

if( verbose ) message( " ... starting assembly" )
result.frame<-cbind(subject.frame,y.frame2,X.frame)
rm(X.frame)

for( inert.type in c( "body_acc", "body_gyro", "total_acc" ) ){
  for( axis in c( "x", "y", "z") ){
    inert.id <- paste( inert.type, "_", axis, sep="" )
    inert.file <- paste( inert.id, "_", set.name, ".txt", sep="" )
    if( verbose ) message( " ... reading ", inert.file )
    inert.frame <- read.table( as.character(file.list[inert.file,]$file) )
    inert.labels <- sapply( c(1:128), function(x){ sprintf( paste( inert.id, '.', "%03d", sep="" ), x ) } )
    colnames(inert.frame) <- inert.labels
    result.frame <- cbind(result.frame,inert.frame)
    rm(inert.frame)
  }
}

if( savefile != "" ){
  if( verbose ) message(  " ... attempting to write to ", savefile )
  write.csv( result.frame, savefile )
}

result.frame
}
```

So now I can read both datasets and stick them together

```{r read and join test and train}
setwd("~/wearable")
test.frame <- assemble_dataset('test')
train.frame <- assemble_dataset('train')
full.frame <- rbind( test.frame, train.frame )
```

Further processing
------------------

What about the subsetting requested in the project assignment? _Extracts only the measurements on the mean and standard deviation for each measurement._.

They ask for the _mean and standard deviation_ for each measurement. I'm going to assume that what they want
are the subject and activity columns, plus all the columns ending in __-mean()__ or __-std()__. I can get this
as a list with this command

```{r requested headings only}
wanted <- grep( 'subject|activity|-mean[(]|-std[(]', colnames(full.frame) )
meanavg.frame <- full.frame[,wanted]
```

What seems to be wanted for part 5 is _Creates a second, independent tidy data set with the average of each variable for each activity and each subject_. So maybe it wants me to average over subjects and activities,
i.e. the means of the __*-mean()__ and the means of the __*-std()__ values for each combination of subject
and activity. Need to go back and look at the lectures for that. Maybe Week 3 _Summarizing Data_.

OK, so some reading later I think it looks like I'm going to be using __aggregate()__ to do the work.
Let's try this:

```{r aggregate from meanavg dataset}
interim.agg.frame<-aggregate(meanavg.frame,by=list(meanavg.frame$subject,meanavg.frame$activity),mean)
```

I don't know how to get rid of those stupid error messages, won't try.

That kinda-sorta did it, except that the __subject__ and __activity__ columns in __interim.agg.frame__ have been
trashed -- you can't average factors. But it's all good because we've got a headings __Group.1__ and
__Group.2__ that have the corresponding data in them, and in the right order too.

I'm going to write my own (doubtless abysmally slow) check routine here to see if __aggregate()__ is
doing what I think it should be.

```{r define dumb_aggregate}
## See if aggregate() is doing what I think
dumb_aggregate <- function( the.frame, subject, activity, variable="tBodyAcc-mean()-X" ){
  rows <- the.frame$subject == subject & the.frame$activity == activity
  values <- the.frame[rows,variable]
  result <- sum(values) / length(values)
  result
}
```

Looks OK. 

So now I need to replace the Group.1 and Group.2 headings in __interim.agg.frame__. _(At this point
I decided to call it interim_agg.frame)_

```{r pick aggregate headings}
agg.headings.wanted <- colnames(interim.agg.frame)[!grepl('subject|activity', colnames(agg.frame))]
agg.frame <- interim.agg.frame[,agg.headings.wanted]
agg.headings.wanted[1]<-'activity'
agg.headings.wanted[2]<-'subject'
colnames(agg.frame)<-agg.headings.wanted
```

And __agg.frame__ is the final result!!!